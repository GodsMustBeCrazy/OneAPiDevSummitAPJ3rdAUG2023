{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9e466e",
   "metadata": {},
   "source": [
    "<font size=\"5\"> **Stable Diffusion Inference on Intel Max GPU** </font> \n",
    "<br>\n",
    "This code sample will perform stable diffusion inference based on the text prompt using KerasCV implementation while using IntelÂ® Extension for Tensorflow*. The following run cases are executed:<br>\n",
    "* FP32 (baseline) <br>\n",
    "* Advanced Auto Mixed Precision FP16 <br>\n",
    "\n",
    "<font size=\"5\">**Environment Setup**</font>  <br>\n",
    "Ensure the **itex_xpu kernel** is activated before running this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7debef3-313f-4841-835a-f8ecec6bceff",
   "metadata": {},
   "source": [
    "### Select an idling GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166707e6-6826-4825-a72c-b388e831a2d5",
   "metadata": {},
   "source": [
    "List all the detected GPU's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb6be16-9c15-4be3-abdf-ac586dc5ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sycl-ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b9c667-de19-4c57-a708-fa9c3a0a5aa2",
   "metadata": {},
   "source": [
    "There are 4 Intel Max GPU's in each compute node. Running the below cell outputs the GPU's operating frequency. Select and use the GPU device id with the lowest operating frequency (indicating low gpu utilization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38018c0e-fda1-4b8e-9be8-c9987662870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python gpu_stat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0738c58b-3d7f-4f45-880a-10bb2f552758",
   "metadata": {},
   "source": [
    "Update the below cell with the gpu device id corresponding to the lowest operating frequency from the above table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3c9321-6522-44f1-9386-8741cb53ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_device = ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a9d25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['ITEX_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['ZE_AFFINITY_MASK'] = str(gpu_device)\n",
    "\n",
    "import time\n",
    "from keras_cv.models.stable_diffusion import StableDiffusion\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425fe3ef-804b-42e4-bee3-f2058330f7d7",
   "metadata": {},
   "source": [
    "<font size =\"5\">**Helper Functions**</font>\n",
    "\n",
    "The functions below will help us plot the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ea0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    png_name = \"{}_{}imgs_{}steps.png\".format(\n",
    "        precision, batch_size, num_steps)\n",
    "    \n",
    "    print(\"Start plotting the generated images to %s\" % (png_name))\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(len(images)):\n",
    "        ax = plt.subplot(1, len(images), i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af220a7",
   "metadata": {},
   "source": [
    "<font size =\"5\">**Model Loading**</font> <br>\n",
    "First, we construct a model and also define few of the required parameters:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb67cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1\n",
    "use_xla = False\n",
    "precision = 'fp32'\n",
    "batch_size = 1\n",
    "num_steps = 50\n",
    "seed= 12345\n",
    "benchmark_result = []\n",
    "\n",
    "model = StableDiffusion(\n",
    "    img_width=512,\n",
    "    img_height=512,\n",
    "    jit_compile=use_xla,   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c260c0",
   "metadata": {},
   "source": [
    "<font size =\"5\">**Running Inference** </font> <br>\n",
    "Next, we give it a prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962f9e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "\n",
    "print(\"Start Warmup\")\n",
    "model.text_to_image(\n",
    "    \"warming up the model\", batch_size=batch_size, num_steps=num_steps\n",
    ")\n",
    "# Start inference\n",
    "print(\"Start running inference and generating images\")\n",
    "t = 0\n",
    "for i in range(iterations):\n",
    "    start_time = time.time()\n",
    "    images = model.text_to_image(prompt=prompt, batch_size=batch_size, seed=seed, num_steps=num_steps)\n",
    "    t+=(time.time() - start_time)\n",
    "print(f\"FP32 precision: {(t/iterations):.2f} seconds\")\n",
    "benchmark_result.append([\"FP32 precision\", t/iterations])\n",
    "plot_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c14ad",
   "metadata": {},
   "source": [
    "<font size=\"4\">**Performance computation using AMP BF16 precision** </font>\n",
    "<br>\n",
    "Enable Advanced AMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d776101-e5b8-4a07-aab8-2e6f38a816cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intel_extension_for_tensorflow as itex\n",
    "print(\"intel_extension_for_tensorflow {}\".format(itex.__version__))\n",
    "\n",
    "auto_mixed_precision_options = itex.AutoMixedPrecisionOptions()\n",
    "auto_mixed_precision_options.data_type = itex.FLOAT16 \n",
    "\n",
    "graph_options = itex.GraphOptions(auto_mixed_precision_options=auto_mixed_precision_options)\n",
    "graph_options.auto_mixed_precision = itex.ON\n",
    "\n",
    "config = itex.ConfigProto(graph_options=graph_options)\n",
    "itex.set_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b90c7e-80fa-48f5-85c6-a2e9c2c4085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "itex.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f566ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StableDiffusion(\n",
    "    img_width=512,\n",
    "    img_height=512,\n",
    "    jit_compile=use_xla\n",
    ")\n",
    "\n",
    "print(\"Start Warmup\")\n",
    "model.text_to_image(\n",
    "    \"warming up the model\", batch_size=batch_size, num_steps=num_steps\n",
    ")\n",
    "# Start inference\n",
    "print(\"Start running inference and generating images\")\n",
    "t = 0\n",
    "for i in range(iterations):\n",
    "    start_time = time.time()\n",
    "    images = model.text_to_image(prompt=prompt, batch_size=batch_size, seed=seed, num_steps=num_steps)\n",
    "    t+=(time.time() - start_time)\n",
    "    \n",
    "print(f\"AMP FP16 precision: {(t/iterations):.2f} seconds\")\n",
    "benchmark_result.append([\"AMP FP16 precision\", t/iterations])\n",
    "plot_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e0a04-1189-480b-8905-39d600b8b0da",
   "metadata": {},
   "source": [
    "<font size =\"5\">**Performance comparison** <br></font>\n",
    "Lets compare the results wrt inference latency time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0803d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:<20} {:<20}\".format(\"Model\", \"Runtime\"))\n",
    "for result in benchmark_result:\n",
    "    name, runtime = result\n",
    "    print(\"{:<20} {:<20}\".format(name, runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create bar chart with training time results\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.title(\"Stable diffusion Inference Time\")\n",
    "plt.ylabel(\"Inference Time (seconds)\")\n",
    "plt.bar([\"FP32\", \"FP16-AMP\"], [benchmark_result[0][1], benchmark_result[1][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d23ab-7336-4fad-9e27-3590c10f3101",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[CODE_SAMPLE_COMPLETED_SUCCESFULLY]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44ead2a-f4fc-4ed5-841e-643ba299b3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itex_xpu",
   "language": "python",
   "name": "itex_xpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
