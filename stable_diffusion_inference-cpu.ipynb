{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9e466e",
   "metadata": {},
   "source": [
    "<font size=\"5\"> **Stable Diffusion Inference for Text2Image on Intel Sapphire Rapids** </font> \n",
    "<br>\n",
    "This code sample will perform stable diffusion inference based on the text prompt using KerasCV implementation while using Intel® Extension for Tensorflow*. The following run cases are executed:<br>\n",
    "* FP32 (baseline) <br>\n",
    "* Advanced AMP for BF16 precision <br>\n",
    "\n",
    "<font size=\"5\">**Environment Setup**</font>  <br>\n",
    "Ensure the **itex_cpu kernel** is activated before running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a9d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['ITEX_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['OMP_NUM_THREADS'] = '8'\n",
    "os.environ['KMP_AFFINITY'] = 'granularity=fine,compact,1,0'\n",
    "os.environ['TF_NUM_INTEROP_THREADS'] = '1'\n",
    "os.environ['TF_NUM_INTRAOP_THREADS'] = '8'\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "from keras_cv.models.stable_diffusion import StableDiffusion\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425fe3ef-804b-42e4-bee3-f2058330f7d7",
   "metadata": {},
   "source": [
    "<font size =\"5\">**Helper Functions**</font>\n",
    "\n",
    "The functions below will help us plot the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ea0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    png_name = \"{}_{}imgs_{}steps.png\".format(\n",
    "        precision, batch_size, num_steps)\n",
    "    \n",
    "    print(\"Start plotting the generated images to %s\" % (png_name))\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(len(images)):\n",
    "        ax = plt.subplot(1, len(images), i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af220a7",
   "metadata": {},
   "source": [
    "<font size =\"5\">**Model Loading**</font> <br>\n",
    "First, we construct a model and also define few of the required parameters:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb67cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1\n",
    "use_xla = False\n",
    "precision = 'fp32'\n",
    "batch_size = 1\n",
    "num_steps = 50\n",
    "seed= 12345\n",
    "benchmark_result = []\n",
    "\n",
    "model = StableDiffusion(\n",
    "    img_width=512,\n",
    "    img_height=512,\n",
    "    jit_compile=use_xla,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c260c0",
   "metadata": {},
   "source": [
    "<font size =\"5\">**Running Inference** </font> <br>\n",
    "Next, we give it a prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962f9e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "\n",
    "print(\"Start Warmup\")\n",
    "model.text_to_image(\n",
    "    \"warming up the model\", batch_size=batch_size, num_steps=num_steps\n",
    ")\n",
    "# Start inference\n",
    "print(\"Start running inference and generating images\")\n",
    "t = 0\n",
    "for i in range(iterations):\n",
    "    start_time = time.time()\n",
    "    images = model.text_to_image(prompt=prompt, batch_size=batch_size, seed=seed, num_steps=num_steps)\n",
    "    t+=(time.time() - start_time)\n",
    "print(f\"FP32 precision: {(t/iterations):.2f} seconds\")\n",
    "benchmark_result.append([\"FP32 precision\", t/iterations])\n",
    "plot_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c14ad",
   "metadata": {},
   "source": [
    "<font size=\"4\">**Performance computation using AMP BF16 precision** </font>\n",
    "<br>\n",
    "Enable Advanced AMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d776101-e5b8-4a07-aab8-2e6f38a816cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intel_extension_for_tensorflow as itex\n",
    "print(\"intel_extension_for_tensorflow {}\".format(itex.__version__))\n",
    "\n",
    "auto_mixed_precision_options = itex.AutoMixedPrecisionOptions()\n",
    "auto_mixed_precision_options.data_type = itex.BFLOAT16 \n",
    "\n",
    "graph_options = itex.GraphOptions(auto_mixed_precision_options=auto_mixed_precision_options)\n",
    "graph_options.auto_mixed_precision = itex.ON\n",
    "\n",
    "config = itex.ConfigProto(graph_options=graph_options)\n",
    "itex.set_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f850cf2-b57c-4e74-b2b7-8be33e83a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "itex.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f566ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StableDiffusion(\n",
    "    img_width=512,\n",
    "    img_height=512,\n",
    "    jit_compile=use_xla\n",
    ")\n",
    "\n",
    "print(\"Start Warmup\")\n",
    "model.text_to_image(\n",
    "    \"warming up the model\", batch_size=batch_size, num_steps=num_steps\n",
    ")\n",
    "# Start inference\n",
    "print(\"Start running inference and generating images\")\n",
    "t = 0\n",
    "for i in range(iterations):\n",
    "    start_time = time.time()\n",
    "    images = model.text_to_image(prompt=prompt, batch_size=batch_size, seed=seed, num_steps=num_steps)\n",
    "    t+=(time.time() - start_time)\n",
    "    \n",
    "print(f\"AMP BF16 precision: {(t/iterations):.2f} seconds\")\n",
    "benchmark_result.append([\"AMP BF16 precision\", t/iterations])\n",
    "plot_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e0a04-1189-480b-8905-39d600b8b0da",
   "metadata": {},
   "source": [
    "<font size =\"5\">**Performance comparison** <br></font>\n",
    "Lets compare the results wrt inference latency time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0803d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:<20} {:<20}\".format(\"Model\", \"Runtime\"))\n",
    "for result in benchmark_result:\n",
    "    name, runtime = result\n",
    "    print(\"{:<20} {:<20}\".format(name, runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create bar chart with training time results\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.title(\"Stable diffusion Inference Time\")\n",
    "plt.ylabel(\"Inference Time (seconds)\")\n",
    "plt.bar([\"FP32\", \"BF16-AMP\"], [benchmark_result[0][1], benchmark_result[1][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de73d92-6c1c-4585-a153-85090e62d929",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b> Legal Notices and Disclaimers</b></summary>\n",
    "Intel technologies’ features and benefits depend on system configuration and may require enabled hardware, software or service activation. Performance varies depending on system configuration. No computer system can be absolutely secure. Check with your system manufacturer or retailer or learn more at www.intel.com.<br>\n",
    "Cost reduction scenarios described including recommendations are intended as examples of how a given Intel-based product, in the specified circumstances and configurations, may affect future costs and provide cost savings. Circumstances will vary. Intel does not guarantee any costs or cost reduction.<br>\n",
    "This document contains information on products, services and/or processes in development. All information provided here is subject to change without notice. Contact your Intel representative to obtain the latest forecast, schedule, specifications and roadmaps. <br>\n",
    "Any forecasts of goods and services needed for Intel’s operations are provided for discussion purposes only. Intel will have no liability to make any purchase in connection with forecasts published in this document.<br>\n",
    "Intel technologies may require enabled hardware, software or service activation.<br>\n",
    "Software and workloads used in performance tests may have been optimized for performance only on Intel microprocessors.  <br>\n",
    "Performance tests, are measured using specific computer systems, components, software, operations and functions.  Any change to any of those factors may cause the results to vary.  You should consult other information and performance tests to assist you in fully evaluating your contemplated purchases, including the performance of that product when combined with other products.   For more complete information visit www.intel.com/benchmarks.<br>\n",
    "\n",
    "|* Other names and brands may be claimed as the property of others. <br>\n",
    "\n",
    "Your costs and results may vary. <br>\n",
    "© Intel Corporation.  Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries.  Other names and brands may be claimed as the property of others.<br>\n",
    "Copyright 2023 Intel Corporation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itex_cpu",
   "language": "python",
   "name": "itex_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
